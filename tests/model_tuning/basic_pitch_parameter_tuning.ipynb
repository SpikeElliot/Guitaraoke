{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd20b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mir_eval\n",
    "import librosa\n",
    "from basic_pitch.inference import Model, predict\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "\n",
    "# Preload the Basic Pitch model\n",
    "MODEL = Model(ICASSP_2022_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbda433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = Path(\"./audio\")\n",
    "ANNOTATION_DIR = Path(\"./annotation\")\n",
    "\n",
    "# Shuffle the data for random split\n",
    "ITEMS = np.stack(\n",
    "    (os.listdir(AUDIO_DIR), os.listdir(ANNOTATION_DIR)),\n",
    "    axis=1\n",
    ")\n",
    "np.random.shuffle(ITEMS)\n",
    "\n",
    "DATASET_SIZE = len(os.listdir(AUDIO_DIR))\n",
    "TEST_SIZE = int(DATASET_SIZE * 0.2)\n",
    "\n",
    "# Move random 20% of data to test set\n",
    "for files in ITEMS[:TEST_SIZE]:\n",
    "    shutil.move(AUDIO_DIR / files[0], \"./test/audio\")\n",
    "    shutil.move(ANNOTATION_DIR / files[1], \"./test/annotation\")\n",
    "\n",
    "# Move the remaining 80% to train set\n",
    "for files in ITEMS[TEST_SIZE:]:\n",
    "    shutil.move(AUDIO_DIR / files[0], \"./train/audio\")\n",
    "    shutil.move(ANNOTATION_DIR / files[1], \"./train/annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a327296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_note_events(note_events: list) -> tuple[np.ndarray, np.ndarray]:\n",
    "    events = []\n",
    "    for e in note_events:\n",
    "        events.append([e[0], e[0]+1e-6, e[2]])\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        events, columns=[\"note_on\", \"note_off\", \"midi_pitch\"]\n",
    "    ).sort_values(\"note_on\")\n",
    "\n",
    "    # Prepare ndarrays for mir_eval\n",
    "    intervals = df[[\"note_on\", \"note_off\"]].to_numpy()\n",
    "    pitches = librosa.midi_to_hz(df[\"midi_pitch\"].to_numpy())\n",
    "\n",
    "    return intervals, pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed8e38",
   "metadata": {},
   "source": [
    "Note intervals need to be in the format of a rank-2 ndarray, and need to be positive (offset > onset) for mir_eval.  \n",
    "\n",
    "Therefore, offsets are set to an arbitrary value (offset + 1e-6) as they will be discounted during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8573a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_note_events(xml_path: str | Path) -> tuple[np.ndarray, np.ndarray]:\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    intervals = []\n",
    "    pitches = []\n",
    "    for event in root.findall(\"./transcription/event\"):\n",
    "        for child in event:\n",
    "            if child.tag == \"onsetSec\":\n",
    "                onset = float(child.text)\n",
    "                intervals.append([onset, onset+1e-6]) # Onset and placeholder offset\n",
    "            elif child.tag == \"pitch\":\n",
    "                pitches.append(int(child.text)) # MIDI note\n",
    "\n",
    "    # Prepare ndarrays for mir_eval\n",
    "    intervals = np.array(intervals)\n",
    "    pitches = librosa.midi_to_hz(np.array(pitches))\n",
    "\n",
    "    return intervals, pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f46563dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_scores(\n",
    "    true_intervals: np.ndarray, \n",
    "    true_pitches: np.ndarray, \n",
    "    pred_intervals: np.ndarray, \n",
    "    pred_pitches: np.ndarray\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Get the performance scores (Precision, Recall, F1, Avg. Overlap Ratio)\n",
    "    of the model's note predictions against the true values.\n",
    "    \"\"\"\n",
    "    scores = mir_eval.transcription.precision_recall_f1_overlap(\n",
    "        true_intervals, true_pitches,\n",
    "        pred_intervals, pred_pitches,\n",
    "        offset_ratio=None # Ignore note offsets\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(params: dict[str], iterations: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Get model note prediction scores on all training data using a random\n",
    "    hyperparameter setup chosen from a provided parameter distributions\n",
    "    dictionary for a given number of iterations.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Get mean performance scores for 10 random hyperparameter setups\n",
    "    for _ in range(iterations):\n",
    "        f1_scores = []\n",
    "        recall_scores = []\n",
    "        precision_scores = []\n",
    "\n",
    "        param_setup = { # Randomly select from param distributions\n",
    "            \"onset_threshold\": np.random.choice(params[\"onset_threshold\"]),\n",
    "            \"frame_threshold\": np.random.choice(params[\"frame_threshold\"]),\n",
    "            \"minimum_note_length\": np.random.choice(params[\"minimum_note_length\"]),\n",
    "            \"minimum_frequency\": np.random.choice(params[\"minimum_frequency\"]),\n",
    "            \"maximum_frequency\": np.random.choice(params[\"maximum_frequency\"]),\n",
    "            \"multiple_pitch_bends\": np.random.choice(params[\"multiple_pitch_bends\"]),\n",
    "            \"melodia_trick\": np.random.choice(params[\"melodia_trick\"])\n",
    "        }\n",
    "\n",
    "        # Make predictions on all training data and save scores\n",
    "        for i, audio_file in enumerate(os.listdir(\"./train/audio\")):\n",
    "            note_events = predict(\n",
    "                audio_path=f\"./train/audio/{audio_file}\",\n",
    "                model_or_model_path=MODEL,\n",
    "                onset_threshold=param_setup[\"onset_threshold\"],\n",
    "                frame_threshold=param_setup[\"frame_threshold\"],\n",
    "                minimum_note_length=param_setup[\"minimum_note_length\"],\n",
    "                minimum_frequency=param_setup[\"minimum_frequency\"],\n",
    "                maximum_frequency=param_setup[\"maximum_frequency\"],\n",
    "                multiple_pitch_bends=param_setup[\"multiple_pitch_bends\"],\n",
    "                melodia_trick=param_setup[\"melodia_trick\"]\n",
    "            )[2]\n",
    "            pred_intervals, pred_pitches = preprocess_note_events(note_events)\n",
    "\n",
    "            annotation_files = os.listdir(\"./train/annotation\")\n",
    "            true_intervals, true_pitches = load_test_note_events(\n",
    "                f\"./train/annotation/{annotation_files[i]}\"\n",
    "            )\n",
    "\n",
    "            scores = classification_scores(\n",
    "                true_intervals, true_pitches,\n",
    "                pred_intervals, pred_pitches\n",
    "            )\n",
    "            precision_scores.append(scores[0])\n",
    "            recall_scores.append(scores[1])\n",
    "            f1_scores.append(scores[2])\n",
    "\n",
    "        # Add hyperparameter setup and mean scores to results list\n",
    "        results.append({\n",
    "            \"param_setup\": param_setup,\n",
    "            \"mean_f1_score\": np.mean(f1_scores),\n",
    "            \"mean_recall_score\": np.mean(recall_scores),\n",
    "            \"mean_precision_score\": np.mean(precision_scores),\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"onset_threshold\": np.linspace(0.1, 0.9),\n",
    "    \"frame_threshold\": np.linspace(0.1, 0.9),\n",
    "    \"minimum_note_length\": np.linspace(70, 140),\n",
    "    \"minimum_frequency\": [None],\n",
    "    \"maximum_frequency\": [None],\n",
    "    \"multiple_pitch_bends\": [True, False],\n",
    "    \"melodia_trick\": [True, False]\n",
    "}\n",
    "\n",
    "random_search(param_distributions, iterations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4419e",
   "metadata": {},
   "source": [
    "### Preliminary Best Hyperparameter Setup:\n",
    "\n",
    "- onset_threshold: **0.753061224489796**\n",
    "\n",
    "- frame_threshold: **0.42653061224489797**\n",
    "\n",
    "- minimum_note_length: **118.57142857142857**\n",
    "\n",
    "- minimum_frequency: **None**\n",
    "\n",
    "- maximum_frequency: **None**\n",
    "\n",
    "- multiple_pitch_bends: **True**\n",
    "\n",
    "- melodia_trick: **False**\n",
    "\n",
    "### Best Model Scores:\n",
    "\n",
    "- mean_f1_score: **0.770**\n",
    "\n",
    "- mean_recall_score: **0.778**\n",
    "\n",
    "- mean_precision_score: **0.798**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
